{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing of the Opensource Enron Email Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains emails between Staff of the Enron corporation, which declared bankrupcy and dissolution in December of 2001. This dataset is the largest collection of opensource emails in respect to internal organizational interaction, and was released as part of a fraud investigation orchestrated by the US Federal Energy Regulatory Commission. The dataset is comprised of over 0.5M emails between around 150 members of Enron staff (mostly senior management), between 1998 and 2002. A substantial number of the emails involve extrernal agents/entities, and also non-identifiable Enron employees. This notebook seeks to highlight the pre-processing needed to make this dataset fully usable, and provide code to facilitate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset\n",
    "Several different versions of this dataset exist, however the data used for this notebook was sourced from work carried out by the Carnegie Mellon University, a link to which can be found [Here](https://www.cs.cmu.edu/~./enron/). The data is in .csv format, and contains the columns 'Date'{2}, 'From'{3}, 'To'{4}, and 'Content'{13}. A number of additional columns are also present that don't contain data, which is why the 'usecols' function has been used. The content column has been defined as string with the 'dtype' function to counter processing problems later on in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('enron_05_17_2015_with_labels_v2.csv', usecols=[2,3,4,13], dtype={13:str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a count of email recipients\n",
    "Emails between staff include:\n",
    "    - Personal communication between two individuals\n",
    "    - Group messages to numerous individuals\n",
    "    - Annoucements to large groups of staff, including emails containing over 100 recipients\n",
    "    \n",
    "As amount of people included in an email may be useful to analyze, a count is developed of how many recipients are in each email. In the 'To' column, emails sent to more than one person are seperated by comma, which is counted by the function below, and then 1 is added for each line to account for the original recipient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Included_In_Email'] = df.To.str.count(',')\n",
    "df['Included_In_Email'] = df['Included_In_Email'].apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping any lines with missing values, and removing announcement emails\n",
    "Numerous emails within the dataset contain null values in the content column, which the function below removes. Additionally, as my own research required emails to be split into individual lines, emails with over 15 recipients are removed to reduce the amount of emails used for final analysis. After these steps, overall email count drops from 517,401 to 457,401."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df['Included_In_Email'] >=15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperating emails into a line-per-recipient format\n",
    "As my research was based around staff networks, emails needed to be seperated into a line-per-line format, which the following function carries out. After splitting emails into an individual recipient format, number of emails increases substantially from 457,401 to 852,253. If you receive an error:\n",
    "\n",
    "ValueError: Length mismatch: Expected axis has 6 elements, new values have 5 elements\n",
    "\n",
    "Ignore it, this does not effect outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-60a474e6a0c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'From'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'content'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Included_In_Email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'To'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'From'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'To'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Included_In_Email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   4383\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4384\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4386\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4387\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   3321\u001b[0m             raise ValueError(\n\u001b[0;32m   3322\u001b[0m                 \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3323\u001b[1;33m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[0;32m   3324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 6 elements, new values have 5 elements"
     ]
    }
   ],
   "source": [
    "df['To'] = df.To.str.split(',')\n",
    "df2 = df.set_index(['From', 'Date', 'content', 'Included_In_Email'])['To'].apply(pd.Series).stack()\n",
    "df2 = df2.reset_index()\n",
    "df2.columns = ['From','To','Date','content', 'Included_In_Email']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'To' column, dropping unneeded column, and changing column order\n",
    "The last function renamed the 'To' column as '0', and added an unneeded column named 'level_4' - the following code is used to drop this unneeded column, and rename 'To'. Additionally, a command is used to sort the columns into a more logical format. The previous dataset 'df' is also removed at this point to avoid clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df2['level_4']\n",
    "df2 = df2.rename(columns = {0: 'To'})\n",
    "df2 = df2[['Date','From','To','content','Included_In_Email']]\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the 'From' and 'To' columns\n",
    "Emails within the above columns are of the format: frozenset({'phillip.allen@enron.com'}). The following functions are used to remove 'frozenset' from both columns, and also to remove unneeded punctuation (such as < or ')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['From'] = df2['From'].map(lambda x: x.lstrip(\"frozenset\"))\n",
    "df2['To'] = df2['To'].map(lambda x: x.lstrip(\"frozenset\"))\n",
    "df2['From'] = df2['From'].str.strip(\"<\\>(/){?}[:]*, \")\n",
    "df2['To'] = df2['To'].str.strip(\"<\\>(/){?}[:]*, \")\n",
    "df2['From'] = df2['From'].str.replace(\"'\", \"\")\n",
    "df2['To'] = df2['To'].str.replace(\"'\", \"\")\n",
    "df2['From'] = df2['From'].str.replace('\"', \"\")\n",
    "df2['To'] = df2['To'].str.replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accounting for users having different emails\n",
    "One staff member can have up to four different emails, so the following code uses a dictionary to convert emails for the same person to only one variant. This dictionary is based on work previoiusly carried out by Andres Corrada-Emmanuel, originally published at [Enron Email Webpage](https://www.cs.cmu.edu/~enron/). I have added several emails to this file that were previously unaccounted for, so my final dictionary can be found on my Enron GitHub page [Here](https://github.com/Laurie-Bamber/Enron_Corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dict = pd.read_csv('dict_email.csv')    \n",
    "df2['From'] = df2.From.replace(email_dict.set_index('Old')['New'])\n",
    "df2['To'] = df2.To.replace(email_dict.set_index('Old')['New'])\n",
    "del email_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing emails not containing the tag 'enron.com'\n",
    "The code below removes all email addresses not containing @enron.com, so only correspondence between Enron staff is left in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Enron'] = df2.From.str.count('@enron')\n",
    "df2['Enron'] = df2['Enron']+df2.To.str.count('@enron')\n",
    "df2 = df2[df2.Enron != 0]\n",
    "df2 = df2[df2.Enron != 1]\n",
    "del df2['Enron']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding job-roles for remaining staff\n",
    "Using a dictionary, two new columns are added to the dataset which contain staff job-roles: 'Sender_Role' and 'Receiver_Role'. This dictionary is based off previous work carried out by Youngser Park, a Research Scientist at the Centre for Imaging Science (CIS), and can be found [Here](http://cis.jhu.edu/~parky/Enron/employees). I have built on this work and included several more employees that I could identify through Google and dataset emails, which can be found on my Enron GitHub page [Here](https://github.com/Laurie-Bamber/Enron_Corpus). This raises the number of identifiable staff to 177, however a substantial number of staff without identifiable roles still remain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('dict_role.csv') as f:\n",
    "    role_dict = dict(filter(None, csv.reader(f)))\n",
    "df2['Sender_Role'] = df2['From'].map(role_dict)\n",
    "df2['Receiver_Role'] = df2['To'].map(role_dict)\n",
    "df2 = df2[['Date','From','To','Sender_Role','Receiver_Role','content','Included_In_Email']]\n",
    "del role_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning content column\n",
    "A substantial amount of non-informative text is found in the content column, mostly in the case of Forwarded messages with extensive subject lines. The text of each fresh email, however, will always follow the tag 'subject: ', so the following code removes all text prior to this tag. Forwarded emails can contain several of these tags, so the .rsplit function is usedy to concentrate on only the last instance of 'subject: '. The dash line below was also included to further clean non-informative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['content'] = df2['content'].str.rsplit('Subject: ').str[-1] \n",
    "df2['content'] = df2['content'].str.rsplit(' --------------------------- ').str[-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code can be used for the purpose of network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condensing multiple emails between two people into one line, and adding weight\n",
    "The following code is used to reduce all the emails between two individuals into one line, with a weight (number of emails) column added for each interaction. As all emails between two individuals are now condensed, the use of the 'Date' and 'Content' columns is now non-applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted = df2.groupby(['From', 'To']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General cleaning after condensing\n",
    "Several unwanted columns are created by condensing the records. The following code subsequently removes these columns, leaving only the columns 'From', 'To', and 'Weight'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted['Weight'] = Weighted['Date']\n",
    "Weighted = Weighted.drop(['Date','Sender_Role','Receiver_Role','content','Included_In_Email'], 1)\n",
    "Weighted.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-adding job-roles to staff\n",
    "Condensing the records also removed job-roles from staff, which the following code subsequently re-adds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_role.csv') as f:\n",
    "    role_dict = dict(filter(None, csv.reader(f)))\n",
    "Weighted['Sender_Role'] = Weighted['From'].map(role_dict)\n",
    "del role_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping email exchanges below a certain frequency\n",
    "Lastly, the following code removes all emails with a weight below a pre-determined threshhold. A weight of <= 3 was determined as appropriate in the case of this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted2 = Weighted[~(Weighted['Weight'] <=3)]\n",
    "Weighted2 = Weighted.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
